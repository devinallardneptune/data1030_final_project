{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Spotify Library Dataset Builder\n",
    "Combines Kaggle dataset with user's Spotify library and adds 'in_library' flag\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyOAuth\n",
    "import time\n",
    "from tqdm.auto import tqdm\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Configuration\n",
    "KAGGLE_DATASET_PATH = 'data/data.csv'\n",
    "OUTPUT_PATH = 'data/final_dataset.csv'\n",
    "\n",
    "load_dotenv()\n",
    "client_id = os.getenv('client_id')\n",
    "client_secret = os.getenv('client_secret')\n",
    "\n",
    "# Spotify API credentials\n",
    "CLIENT_ID = client_id\n",
    "CLIENT_SECRET = client_secret\n",
    "REDIRECT_URI = \"http://127.0.0.1:8080\"\n",
    "SCOPE = 'user-library-read'\n",
    "\n",
    "\n",
    "def setup_spotify_client():\n",
    "    \"\"\"Initialize Spotify client with authentication\"\"\"\n",
    "    auth_manager = SpotifyOAuth(\n",
    "        client_id=CLIENT_ID,\n",
    "        client_secret=CLIENT_SECRET,\n",
    "        redirect_uri=REDIRECT_URI,\n",
    "        scope=SCOPE\n",
    "    )\n",
    "    sp = spotipy.Spotify(auth_manager=auth_manager)\n",
    "    return sp\n",
    "\n",
    "\n",
    "def get_all_saved_tracks(sp):\n",
    "    \"\"\"\n",
    "    Fetch all tracks from user's Spotify library (basic info only)\n",
    "    Returns a list of track dictionaries\n",
    "    Note: Audio features are deprecated, so we only fetch basic track info\n",
    "    and rely on the Kaggle dataset for audio features\n",
    "    \"\"\"\n",
    "    saved_tracks = []\n",
    "    offset = 0\n",
    "    limit = 50  # Max allowed by Spotify API\n",
    "    \n",
    "    print(\"Fetching your saved tracks from Spotify...\")\n",
    "    print(\"Note: Audio features API is deprecated. We'll match your library\")\n",
    "    print(\"tracks with the Kaggle dataset to get audio features.\")\n",
    "    \n",
    "    try:\n",
    "        # Get first batch to determine total\n",
    "        results = sp.current_user_saved_tracks(limit=limit, offset=offset)\n",
    "        total = results['total']\n",
    "        \n",
    "        print(f\"Total tracks in your library: {total}\")\n",
    "        \n",
    "        # Handle empty library\n",
    "        if total == 0:\n",
    "            print(\"Your library is empty!\")\n",
    "            return []\n",
    "        \n",
    "        # Use tqdm for progress bar\n",
    "        with tqdm(total=total, desc=\"Downloading library\") as pbar:\n",
    "            while offset < total:\n",
    "                try:\n",
    "                    results = sp.current_user_saved_tracks(limit=limit, offset=offset)\n",
    "                    \n",
    "                    # Check if we got any items\n",
    "                    if not results or not results.get('items'):\n",
    "                        break\n",
    "                    \n",
    "                    # Extract basic track info\n",
    "                    for item in results['items']:\n",
    "                        track = item.get('track')\n",
    "                        if track and track.get('id'):\n",
    "                            # Extract year from release_date\n",
    "                            release_date = track.get('album', {}).get('release_date', '')\n",
    "                            year = release_date.split('-')[0] if release_date else None\n",
    "                            \n",
    "                            saved_tracks.append({\n",
    "                                'id': track['id'],\n",
    "                                'name': track.get('name', 'Unknown'),\n",
    "                                'artist': track['artists'][0]['name'] if track.get('artists') and len(track['artists']) > 0 else 'Unknown',\n",
    "                                'album': track['album']['name'] if track.get('album') else 'Unknown',\n",
    "                                'year': year,\n",
    "                                'duration_ms': track.get('duration_ms'),\n",
    "                                'explicit': track.get('explicit', False),\n",
    "                                'popularity': track.get('popularity')\n",
    "                            })\n",
    "                    \n",
    "                    pbar.update(len(results['items']))\n",
    "                    \n",
    "                    # Check if there are more tracks\n",
    "                    if results['next'] is None or len(results['items']) == 0:\n",
    "                        break\n",
    "                    \n",
    "                    offset += limit\n",
    "                    time.sleep(0.1)  # Be nice to the API\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"\\nError fetching tracks at offset {offset}: {e}\")\n",
    "                    print(\"Continuing with tracks fetched so far...\")\n",
    "                    break\n",
    "        \n",
    "        print(f\"Successfully fetched {len(saved_tracks)} tracks from your library\")\n",
    "        print(f\"Audio features will be matched from the Kaggle dataset\")\n",
    "        return saved_tracks\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error initializing library fetch: {e}\")\n",
    "        print(\"Make sure you're authenticated and have granted the correct permissions.\")\n",
    "        return []\n",
    "\n",
    "\n",
    "def load_kaggle_dataset(file_path):\n",
    "    \"\"\"Load the Kaggle Spotify dataset\"\"\"\n",
    "    print(f\"Loading Kaggle dataset from {file_path}...\")\n",
    "    df = pd.read_csv(file_path)\n",
    "    print(f\"Loaded {len(df)} tracks from Kaggle dataset\")\n",
    "    print(f\"Columns in dataset: {df.columns.tolist()}\")\n",
    "    return df\n",
    "\n",
    "\n",
    "def create_track_identifier(row, id_col='id', name_col='name', artist_col='artists'):\n",
    "    \"\"\"\n",
    "    Create a unique identifier for matching tracks\n",
    "    Handles different possible column names in Kaggle dataset\n",
    "    \"\"\"\n",
    "    # Try to use Spotify ID first (most reliable)\n",
    "    if id_col in row.index and pd.notna(row[id_col]):\n",
    "        return str(row[id_col]).strip()\n",
    "    \n",
    "    # Fallback to name+artist combination\n",
    "    name = str(row[name_col]).lower().strip() if name_col in row.index else ''\n",
    "    artist = str(row[artist_col]).lower().strip() if artist_col in row.index else ''\n",
    "    \n",
    "    return f\"{name}||{artist}\"\n",
    "\n",
    "\n",
    "def merge_datasets(kaggle_df, library_tracks):\n",
    "    \"\"\"\n",
    "    Merge Kaggle dataset with user's library\n",
    "    Add 'in_library' column\n",
    "    \"\"\"\n",
    "    print(\"\\nMerging datasets...\")\n",
    "    print(f\"Kaggle dataset shape: {kaggle_df.shape}\")\n",
    "    print(f\"Library tracks count: {len(library_tracks)}\")\n",
    "    \n",
    "    if kaggle_df is None or len(kaggle_df) == 0:\n",
    "        print(\"Error: Kaggle dataset is empty or None\")\n",
    "        return None\n",
    "    \n",
    "    # Create set of track IDs from user's library for fast lookup\n",
    "    library_ids = {track['id'] for track in library_tracks if track.get('id')}\n",
    "    \n",
    "    # Also create name+artist combinations as backup\n",
    "    library_name_artist = {\n",
    "        f\"{track['name'].lower().strip()}||{track['artist'].lower().strip()}\"\n",
    "        for track in library_tracks\n",
    "        if track.get('name') and track.get('artist')\n",
    "    }\n",
    "    \n",
    "    print(f\"Library contains {len(library_ids)} unique track IDs\")\n",
    "    \n",
    "    # Determine column names in Kaggle dataset\n",
    "    possible_id_cols = ['id', 'track_id', 'spotify_id']\n",
    "    possible_name_cols = ['name', 'track_name', 'song_name']\n",
    "    possible_artist_cols = ['artists', 'artist', 'artist_name']\n",
    "    \n",
    "    id_col = next((col for col in possible_id_cols if col in kaggle_df.columns), None)\n",
    "    name_col = next((col for col in possible_name_cols if col in kaggle_df.columns), None)\n",
    "    artist_col = next((col for col in possible_artist_cols if col in kaggle_df.columns), None)\n",
    "    \n",
    "    print(f\"Using columns: id='{id_col}', name='{name_col}', artist='{artist_col}'\")\n",
    "    \n",
    "    # Add 'in_library' column\n",
    "    def check_in_library(row):\n",
    "        # Try matching by Spotify ID first\n",
    "        if id_col and id_col in row.index and pd.notna(row[id_col]):\n",
    "            track_id = str(row[id_col]).strip()\n",
    "            if track_id in library_ids:\n",
    "                return 1\n",
    "        \n",
    "        # Fallback to name+artist matching\n",
    "        if name_col and artist_col:\n",
    "            identifier = create_track_identifier(row, id_col, name_col, artist_col)\n",
    "            if identifier in library_name_artist:\n",
    "                return 1\n",
    "        \n",
    "        return 0\n",
    "    \n",
    "    print(\"Flagging tracks in your library...\")\n",
    "    tqdm.pandas(desc=\"Processing tracks\")\n",
    "    kaggle_df['in_library'] = kaggle_df.progress_apply(check_in_library, axis=1)\n",
    "    \n",
    "    matches = kaggle_df['in_library'].sum()\n",
    "    print(f\"\\nFound {matches} tracks from your library in the Kaggle dataset\")\n",
    "    if len(library_tracks) > 0:\n",
    "        print(f\"Match rate: {matches/len(library_tracks)*100:.1f}%\")\n",
    "    \n",
    "    print(f\"Returning dataset with shape: {kaggle_df.shape}\")\n",
    "    print(f\"'in_library' column added: {'in_library' in kaggle_df.columns}\")\n",
    "    print(f\"Dataset type: {type(kaggle_df)}\")\n",
    "    \n",
    "    # Explicit verification before return\n",
    "    if kaggle_df is None:\n",
    "        print(\"ERROR: Dataset is None before return!\")\n",
    "        return None\n",
    "    \n",
    "    if 'in_library' not in kaggle_df.columns:\n",
    "        print(\"ERROR: 'in_library' column missing before return!\")\n",
    "        return None\n",
    "        \n",
    "    return kaggle_df\n",
    "\n",
    "\n",
    "def check_missing_library_tracks(kaggle_df, library_tracks):\n",
    "    \"\"\"\n",
    "    Report on tracks from user's library that aren't in Kaggle dataset\n",
    "    Since audio features API is deprecated, we can't fetch them for missing tracks\n",
    "    \"\"\"\n",
    "    print(\"\\nChecking for library tracks missing from Kaggle dataset...\")\n",
    "    \n",
    "    # Determine ID column\n",
    "    possible_id_cols = ['id', 'track_id', 'spotify_id']\n",
    "    id_col = next((col for col in possible_id_cols if col in kaggle_df.columns), None)\n",
    "    \n",
    "    if not id_col:\n",
    "        print(\"Warning: Could not find ID column. Skipping missing tracks check.\")\n",
    "        return kaggle_df\n",
    "    \n",
    "    kaggle_ids = set(kaggle_df[id_col].dropna().astype(str))\n",
    "    library_ids = {track['id'] for track in library_tracks if track['id']}\n",
    "    missing_ids = library_ids - kaggle_ids\n",
    "    \n",
    "    print(f\"Found {len(missing_ids)} tracks in your library not in Kaggle dataset\")\n",
    "    \n",
    "    if len(missing_ids) > 0:\n",
    "        print(\"\\nNote: These tracks cannot be added to the dataset because\")\n",
    "        print(\"Spotify's audio features API has been deprecated.\")\n",
    "        print(\"Your ML model will only train on tracks present in the Kaggle dataset.\")\n",
    "        print(f\"\\nCoverage: {len(library_ids - missing_ids)}/{len(library_ids)} \")\n",
    "        print(f\"({(len(library_ids - missing_ids)/len(library_ids)*100):.1f}%) of your library tracks are in the dataset\")\n",
    "        \n",
    "        # Show some examples of missing tracks\n",
    "        missing_tracks = [t for t in library_tracks if t['id'] in missing_ids]\n",
    "        if len(missing_tracks) > 0:\n",
    "            print(\"\\nExample missing tracks:\")\n",
    "            for track in missing_tracks[:5]:\n",
    "                print(f\"  - {track['name']} by {track['artist']}\")\n",
    "    \n",
    "    return kaggle_df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"Main execution function\"\"\"\n",
    "    print(\"=\" * 60)\n",
    "    print(\"Spotify Library Dataset Builder\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Step 1: Load Kaggle dataset\n",
    "    kaggle_df = load_kaggle_dataset(KAGGLE_DATASET_PATH)\n",
    "    if kaggle_df is None or len(kaggle_df) == 0:\n",
    "        print(\"Error: Failed to load Kaggle dataset. Exiting.\")\n",
    "        return None\n",
    "    \n",
    "    # Step 2: Setup Spotify client\n",
    "    print(\"\\nAuthenticating with Spotify...\")\n",
    "    sp = setup_spotify_client()\n",
    "    print(\"Successfully authenticated!\")\n",
    "    \n",
    "    # Step 3: Get user's saved tracks\n",
    "    library_tracks = get_all_saved_tracks(sp)\n",
    "    if len(library_tracks) == 0:\n",
    "        print(\"Warning: No tracks found in your library.\")\n",
    "        user_choice = input(\"Continue anyway? (y/n): \").lower()\n",
    "        if user_choice != 'y':\n",
    "            return None\n",
    "    \n",
    "    # Step 4: Merge datasets\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"MERGING DATASETS\")\n",
    "    print(\"=\" * 60)\n",
    "    final_df = merge_datasets(kaggle_df.copy(), library_tracks)\n",
    "    \n",
    "    # Verify merge was successful\n",
    "    if final_df is None:\n",
    "        print(\"Error: Merge failed, final_df is None\")\n",
    "        return None\n",
    "    \n",
    "    if 'in_library' not in final_df.columns:\n",
    "        print(\"Error: 'in_library' column not found after merge\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"✓ Merge successful! Dataset shape: {final_df.shape}\")\n",
    "    print(f\"✓ 'in_library' column present: {final_df['in_library'].sum()} tracks flagged\")\n",
    "    \n",
    "    if final_df is None:\n",
    "        print(\"Error: Dataset became None after adding missing tracks\")\n",
    "        return None\n",
    "    \n",
    "    # Step 6: Save final dataset\n",
    "    print(f\"\\nSaving final dataset to {OUTPUT_PATH}...\")\n",
    "    try:\n",
    "        final_df.to_csv(OUTPUT_PATH, index=False)\n",
    "        print(f\"✓ Dataset successfully saved!\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving dataset: {e}\")\n",
    "        return None\n",
    "    \n",
    "    # Print summary statistics\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"SUMMARY\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Total tracks in dataset: {len(final_df)}\")\n",
    "    print(f\"Tracks in your library: {final_df['in_library'].sum()}\")\n",
    "    print(f\"Tracks not in your library: {(final_df['in_library'] == 0).sum()}\")\n",
    "    print(f\"Percentage in library: {final_df['in_library'].mean() * 100:.2f}%\")\n",
    "    print(f\"\\nDataset saved to: {OUTPUT_PATH}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Show sample of data\n",
    "    print(\"\\nSample of the final dataset:\")\n",
    "    print(final_df.head(10))\n",
    "    print(\"\\nColumns:\", final_df.columns.tolist())\n",
    "    print(\"\\nLibrary tracks sample:\")\n",
    "    if final_df['in_library'].sum() > 0:\n",
    "        print(final_df[final_df['in_library'] == 1].head(5))\n",
    "    \n",
    "    return final_df\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data1030",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
